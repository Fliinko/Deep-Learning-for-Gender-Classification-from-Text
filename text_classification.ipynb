{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.feature_extraction\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender classification assignment\n",
    "\n",
    "You are to follow the instructions below and fill each cell as instructed.\n",
    "Once ready, submit this notebook on VLE with all the outputs included (run all your code and don't clear any output cells).\n",
    "Do not submit anything else apart from the notebook and do not use any extra data apart from what is provided.\n",
    "\n",
    "You will be working on classifying the genders of people from their blog posts using a data set called the [Blog Authorship Corpus](https://www.kaggle.com/rtatman/blog-authorship-corpus).\n",
    "This has been pre-split and reduced for you to use in this assignment.\n",
    "\n",
    "10% of the marks from this assignment are based on neatness.\n",
    "\n",
    "This assignment will carry 40% of the final mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing (10%)\n",
    "\n",
    "You have a train/dev/test split data set consisting of CSV files with two fields: gender and text.\n",
    "The gender field contains either 'male' or 'female' whilst the text is a string containing text from blog posts.\n",
    "\n",
    "Do the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load these three CSV files and tokenise each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  gender\n",
      "0                                                [text]  gender\n",
      "1     ['People, who, feel, good, about, themselves, ...    male\n",
      "2     [We, just, wan, na, say, that, tongue, rings, ...    male\n",
      "3     [urlLink, Extreme, Round, of, the, heat, compe...    male\n",
      "4     [IMPORTANT, UPDATE, It, is, VITAL, that, peopl...    male\n",
      "...                                                 ...     ...\n",
      "4646  [urlLink, YES, !, The, house, takes, shape, ar...  female\n",
      "4647  [Yay, !, !, !, It, 's, ALIVE, and, it, works, ...  female\n",
      "4648  [urlLink, A, picture, every, five, minutes, du...  female\n",
      "4649  [urlLink, Kaitlin, ,, Eri, ,, and, some, rando...  female\n",
      "4650  [I, ca, n't, remember, the, name, of, this, .,...  female\n",
      "\n",
      "[4651 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def load(file):\n",
    "    data = pd.read_csv(file, header=None) # read the csv\n",
    "    data.columns = ['text', 'gender'] # add column names\n",
    "    return data\n",
    "\n",
    "dev = load('dev.csv')\n",
    "test = load('test.csv')\n",
    "train = load('train.csv')\n",
    "\n",
    "dev['text'] = dev.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "test['text'] = test.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "train['text'] = train.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that counts the number of lines in each data set as well as the maximum number of tokens in each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each data set's labels (gender) into numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a vocabulary consisting of the tokens that occur at least 5 times in the train set and output the size of your vocabulary.\n",
    "Include the unknown token and pad token in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create binary bag of words feature vectors for all data set texts using the vocabulary created above (include stop words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data set of indexified token sequences for all texts using the vocabulary created above, making use of unknown tokens and pad tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that counts the percentage of tokens in each data set that are unknown tokens (not including pad tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression classification (20%)\n",
    "\n",
    "Write a linear regression classifier (single layer neural net) that is trained to classify the author gender from the bag of words vector of the text.\n",
    "You do not need to perform any hyperparameter tuning.\n",
    "Use L1 weight decay regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, w0, w1, b):\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0, dtype=torch.float32)\n",
    "        self.w1 = torch.tensor(w1, dtype=torch.float32)\n",
    "        self.b = torch.tensor(b, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x0, x1):\n",
    "        return self.w0*x0 + self.w1*x1 + self.b\n",
    "\n",
    "model = Linear(1, 1, -1)\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy, precision, recall, and F1-score of this classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that shows the top 10 tokens that are the most important for determining the author gender according to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that, for each data split and gender, shows the percentage of rows that include at least one of these important words (so 6 percentages in all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning classifier (50%)\n",
    "\n",
    "Perform hyperparameter tuning on a deep learning classifier (with a convolutional neural network or a recurrent neural network) that is trained to classify the author gender from the indexified sequences of the text.\n",
    "Using the dev set for evaluation.\n",
    "Output the best hyperparameters found and do not store the best trained model as you will be training it again in the next bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the hyperparameters found in the previous bit to train the classifier, this time outputting a graph showing the dev set accuracy after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy, precision, recall, and F1-score of this classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a confusion matrix of the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output 5 examples of correctly classified text for each gender and 5 examples of incorrectly classified text for each gender (so 20 text examples in total), all of which must be from the test set.\n",
    "This is assuming that you have at least 5 instances of each group.\n",
    "If you have less, then show whatever is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the list of important tokens determined previously (from the logistic regression classifier)?\n",
    "Write code that takes all the texts in the test set that have at least one of the important tokens and shows the percentage of these texts that were correctly classified.\n",
    "Similarly, take all the texts that don't have any of the important tokens and show the percentage of these texts that were correctly classified (so 2 percentages in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion (10%)\n",
    "\n",
    "Write, in less than 300 words, your interpretation of the results and how you think the model could perform better.\n",
    "You should talk about things like overfitting/underfitting and whether the model is learning anything deep about how the different genders write or if it's just basing everything on the words used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75ee2b71ad44bf9ef4e9bee896f68ffbc764a6a2c6d1f57c86c48f99ffc25ca8"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
